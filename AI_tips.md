# Tips & Lessons Learned for Using LLM-based Tools (ChatGPT, GitHub Copilot, etc.)

Based on reflections from previous students and research:

## When LLM-based tools are helpful
- Debugging code and improving readability  
- Understanding functions and clarifying documentation  
- Generating plotting code (legends, error bars, layouts)  
- Simplifying complex explanations  
- Brainstorming project ideas  

## Limitations and pitfalls
- **Accuracy issues**: These tools can produce wrong or misleading answers. Always check results.  
- **Over-reliance**: Risk of letting these tools  “do the work” instead of learning.  
- **Shallow understanding**: Summaries often lack scientific depth and context.  
- **Passive learning**: Quick fixes can reduce motivation to engage with material.  

## How to use LLM-based tools effectively
- 🎯 Ask specific, targeted questions  
- 🔁 Use follow-ups to refine answers  
- 🧠 Think critically and fact-check outputs  
- 📚 Balance their support with textbooks, papers, and lectures  
- ✍️ Reflect on when they helped and when they misled you  

## Overall student impressions
- Many found tools like ChatGPT or Copilot increased productivity, especially for coding.  
- Some saw little added value when they already had strong skills.  
- Most agreed they are useful if used responsibly, but harmful if they replace active engagement.  

## Research evidence
Recent research supports these reflections:  

- [PNAS 2025 study](https://www.pnas.org/doi/10.1073/pnas.2422633122) showed that ChatGPT does **not make students smarter** — it only gives the *appearance* of competence.  
- Even with carefully designed “Tutor-GPT”, students did **no better** than those studying with textbooks.  
- With unrestricted use of ChatGPT, students performed **significantly worse**.  

### Lesson learned
LLM-based tools are most valuable as a **companion** rather than a **substitute**.  
Their true potential lies in **enhancing and complementing** traditional learning — not replacing it.
